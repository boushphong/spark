{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.option('header',True).option('sep',';').option('inferSchema',True).csv('/storage/business_zone/users/phongbd5/applied_ds/bank-full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+-------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+---+\n",
      "|age|         job|marital|education|default|balance|housing|loan|contact|day|month|duration|campaign|pdays|previous|poutcome|  y|\n",
      "+---+------------+-------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+---+\n",
      "| 58|  management|married| tertiary|     no|   2143|    yes|  no|unknown|  5|  may|     261|       1|   -1|       0| unknown| no|\n",
      "| 44|  technician| single|secondary|     no|     29|    yes|  no|unknown|  5|  may|     151|       1|   -1|       0| unknown| no|\n",
      "| 33|entrepreneur|married|secondary|     no|      2|    yes| yes|unknown|  5|  may|      76|       1|   -1|       0| unknown| no|\n",
      "| 47| blue-collar|married|  unknown|     no|   1506|    yes|  no|unknown|  5|  may|      92|       1|   -1|       0| unknown| no|\n",
      "| 33|     unknown| single|  unknown|     no|      1|     no|  no|unknown|  5|  may|     198|       1|   -1|       0| unknown| no|\n",
      "+---+------------+-------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('age', 'int'),\n",
       " ('job', 'string'),\n",
       " ('marital', 'string'),\n",
       " ('education', 'string'),\n",
       " ('default', 'string'),\n",
       " ('balance', 'int'),\n",
       " ('housing', 'string'),\n",
       " ('loan', 'string'),\n",
       " ('contact', 'string'),\n",
       " ('day', 'int'),\n",
       " ('month', 'string'),\n",
       " ('duration', 'int'),\n",
       " ('campaign', 'int'),\n",
       " ('pdays', 'int'),\n",
       " ('previous', 'int'),\n",
       " ('poutcome', 'string'),\n",
       " ('y', 'string')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [_[0] for _ in df.dtypes if _[1] == 'int']\n",
    "char_cols = [_[0] for _ in df.dtypes if _[1] == 'string']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['job',\n",
       " 'marital',\n",
       " 'education',\n",
       " 'default',\n",
       " 'housing',\n",
       " 'loan',\n",
       " 'contact',\n",
       " 'month',\n",
       " 'poutcome',\n",
       " 'y']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'job',\n",
       " 'marital',\n",
       " 'education',\n",
       " 'default',\n",
       " 'balance',\n",
       " 'housing',\n",
       " 'loan',\n",
       " 'contact',\n",
       " 'day',\n",
       " 'month',\n",
       " 'duration',\n",
       " 'campaign',\n",
       " 'pdays',\n",
       " 'previous',\n",
       " 'poutcome',\n",
       " 'y']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexers = [StringIndexer(inputCol = _, outputCol= _ + '_index' , handleInvalid = \"keep\") for _ in char_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=indexers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed = pipeline.fit(df).transform(df).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45211"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transformed.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+--------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+---+---------+-------------+---------------+-------------+-------------+----------+-------------+-----------+--------------+-------+\n",
      "|age|         job| marital|education|default|balance|housing|loan|contact|day|month|duration|campaign|pdays|previous|poutcome|  y|job_index|marital_index|education_index|default_index|housing_index|loan_index|contact_index|month_index|poutcome_index|y_index|\n",
      "+---+------------+--------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+---+---------+-------------+---------------+-------------+-------------+----------+-------------+-----------+--------------+-------+\n",
      "| 58|  management| married| tertiary|     no|   2143|    yes|  no|unknown|  5|  may|     261|       1|   -1|       0| unknown| no|      1.0|          0.0|            1.0|          0.0|          0.0|       0.0|          1.0|        0.0|           0.0|    0.0|\n",
      "| 44|  technician|  single|secondary|     no|     29|    yes|  no|unknown|  5|  may|     151|       1|   -1|       0| unknown| no|      2.0|          1.0|            0.0|          0.0|          0.0|       0.0|          1.0|        0.0|           0.0|    0.0|\n",
      "| 33|entrepreneur| married|secondary|     no|      2|    yes| yes|unknown|  5|  may|      76|       1|   -1|       0| unknown| no|      7.0|          0.0|            0.0|          0.0|          0.0|       1.0|          1.0|        0.0|           0.0|    0.0|\n",
      "| 47| blue-collar| married|  unknown|     no|   1506|    yes|  no|unknown|  5|  may|      92|       1|   -1|       0| unknown| no|      0.0|          0.0|            3.0|          0.0|          0.0|       0.0|          1.0|        0.0|           0.0|    0.0|\n",
      "| 33|     unknown|  single|  unknown|     no|      1|     no|  no|unknown|  5|  may|     198|       1|   -1|       0| unknown| no|     11.0|          1.0|            3.0|          0.0|          1.0|       0.0|          1.0|        0.0|           0.0|    0.0|\n",
      "| 35|  management| married| tertiary|     no|    231|    yes|  no|unknown|  5|  may|     139|       1|   -1|       0| unknown| no|      1.0|          0.0|            1.0|          0.0|          0.0|       0.0|          1.0|        0.0|           0.0|    0.0|\n",
      "| 28|  management|  single| tertiary|     no|    447|    yes| yes|unknown|  5|  may|     217|       1|   -1|       0| unknown| no|      1.0|          1.0|            1.0|          0.0|          0.0|       1.0|          1.0|        0.0|           0.0|    0.0|\n",
      "| 42|entrepreneur|divorced| tertiary|    yes|      2|    yes|  no|unknown|  5|  may|     380|       1|   -1|       0| unknown| no|      7.0|          2.0|            1.0|          1.0|          0.0|       0.0|          1.0|        0.0|           0.0|    0.0|\n",
      "| 58|     retired| married|  primary|     no|    121|    yes|  no|unknown|  5|  may|      50|       1|   -1|       0| unknown| no|      5.0|          0.0|            2.0|          0.0|          0.0|       0.0|          1.0|        0.0|           0.0|    0.0|\n",
      "| 43|  technician|  single|secondary|     no|    593|    yes|  no|unknown|  5|  may|      55|       1|   -1|       0| unknown| no|      2.0|          1.0|            0.0|          0.0|          0.0|       0.0|          1.0|        0.0|           0.0|    0.0|\n",
      "+---+------------+--------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+---+---------+-------------+---------------+-------------+-------------+----------+-------------+-----------+--------------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_transformed.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed = df_transformed.drop(*char_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in df_transformed.columns:\n",
    "    if _.endswith('_index'):\n",
    "        df_transformed = df_transformed.withColumnRenamed(_, _[0:-6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- balance: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- campaign: integer (nullable = true)\n",
      " |-- pdays: integer (nullable = true)\n",
      " |-- previous: integer (nullable = true)\n",
      " |-- job: double (nullable = false)\n",
      " |-- marital: double (nullable = false)\n",
      " |-- education: double (nullable = false)\n",
      " |-- default: double (nullable = false)\n",
      " |-- housing: double (nullable = false)\n",
      " |-- loan: double (nullable = false)\n",
      " |-- contact: double (nullable = false)\n",
      " |-- month: double (nullable = false)\n",
      " |-- poutcome: double (nullable = false)\n",
      " |-- y: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_transformed.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols = df_transformed.columns[0:-1], outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+--------+--------+-----+--------+----+-------+---------+-------+-------+----+-------+-----+--------+---+--------------------+\n",
      "|age|balance|day|duration|campaign|pdays|previous| job|marital|education|default|housing|loan|contact|month|poutcome|  y|            features|\n",
      "+---+-------+---+--------+--------+-----+--------+----+-------+---------+-------+-------+----+-------+-----+--------+---+--------------------+\n",
      "| 58|   2143|  5|     261|       1|   -1|       0| 1.0|    0.0|      1.0|    0.0|    0.0| 0.0|    1.0|  0.0|     0.0|0.0|(16,[0,1,2,3,4,5,...|\n",
      "| 44|     29|  5|     151|       1|   -1|       0| 2.0|    1.0|      0.0|    0.0|    0.0| 0.0|    1.0|  0.0|     0.0|0.0|(16,[0,1,2,3,4,5,...|\n",
      "| 33|      2|  5|      76|       1|   -1|       0| 7.0|    0.0|      0.0|    0.0|    0.0| 1.0|    1.0|  0.0|     0.0|0.0|(16,[0,1,2,3,4,5,...|\n",
      "| 47|   1506|  5|      92|       1|   -1|       0| 0.0|    0.0|      3.0|    0.0|    0.0| 0.0|    1.0|  0.0|     0.0|0.0|(16,[0,1,2,3,4,5,...|\n",
      "| 33|      1|  5|     198|       1|   -1|       0|11.0|    1.0|      3.0|    0.0|    1.0| 0.0|    1.0|  0.0|     0.0|0.0|[33.0,1.0,5.0,198...|\n",
      "| 35|    231|  5|     139|       1|   -1|       0| 1.0|    0.0|      1.0|    0.0|    0.0| 0.0|    1.0|  0.0|     0.0|0.0|(16,[0,1,2,3,4,5,...|\n",
      "| 28|    447|  5|     217|       1|   -1|       0| 1.0|    1.0|      1.0|    0.0|    0.0| 1.0|    1.0|  0.0|     0.0|0.0|[28.0,447.0,5.0,2...|\n",
      "| 42|      2|  5|     380|       1|   -1|       0| 7.0|    2.0|      1.0|    1.0|    0.0| 0.0|    1.0|  0.0|     0.0|0.0|[42.0,2.0,5.0,380...|\n",
      "| 58|    121|  5|      50|       1|   -1|       0| 5.0|    0.0|      2.0|    0.0|    0.0| 0.0|    1.0|  0.0|     0.0|0.0|(16,[0,1,2,3,4,5,...|\n",
      "| 43|    593|  5|      55|       1|   -1|       0| 2.0|    1.0|      0.0|    0.0|    0.0| 0.0|    1.0|  0.0|     0.0|0.0|(16,[0,1,2,3,4,5,...|\n",
      "+---+-------+---+--------+--------+-----+--------+----+-------+---------+-------+-------+----+-------+-----+--------+---+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assembler.transform(df_transformed).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_df = df_transformed.select(*num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[age: int, balance: int, day: int, duration: int, campaign: int, pdays: int, previous: int]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = linear_df.columns.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list.remove('balance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=features_list, outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_df = assembler.transform(df_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression(featuresCol='features', labelCol='balance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_model = reg.fit(linear_df) # fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression_4e57ac40288ce7d273a9"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the coefficients and intercepts for each variable\n",
    "import pandas as pd\n",
    "for k, v in linear_df.schema[\"features\"].metadata[\"ml_attr\"][\"attrs\"].items():\n",
    "    features_df = pd.DataFrame(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28.08397290892997,3.3055463619496286,0.24882841970901756,-14.142676297161454,-0.08248810233032043,23.462992800762525] 124.92130092818479\n"
     ]
    }
   ],
   "source": [
    "print(reg_model.coefficients, reg_model.intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df['coefficients'] = reg_model.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>name</th>\n",
       "      <th>coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>age</td>\n",
       "      <td>28.083973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>day</td>\n",
       "      <td>3.305546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>duration</td>\n",
       "      <td>0.248828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>campaign</td>\n",
       "      <td>-14.142676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>pdays</td>\n",
       "      <td>-0.082488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>previous</td>\n",
       "      <td>23.462993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx      name  coefficients\n",
       "0    0       age     28.083973\n",
       "1    1       day      3.305546\n",
       "2    2  duration      0.248828\n",
       "3    3  campaign    -14.142676\n",
       "4    4     pdays     -0.082488\n",
       "5    5  previous     23.462993"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+--------+--------+-----+--------+----+-------+---------+-------+-------+----+-------+-----+--------+---+--------------------+------------------+\n",
      "|age|balance|day|duration|campaign|pdays|previous| job|marital|education|default|housing|loan|contact|month|poutcome|  y|            features|        prediction|\n",
      "+---+-------+---+--------+--------+-----+--------+----+-------+---------+-------+-------+----+-------+-----+--------+---+--------------------+------------------+\n",
      "| 58|   2143|  5|     261|       1|   -1|       0| 1.0|    0.0|      1.0|    0.0|    0.0| 0.0|    1.0|  0.0|     0.0|0.0|[58.0,5.0,261.0,1...|1821.2034908050935|\n",
      "| 44|     29|  5|     151|       1|   -1|       0| 2.0|    1.0|      0.0|    0.0|    0.0| 0.0|    1.0|  0.0|     0.0|0.0|[44.0,5.0,151.0,1...| 1400.656743912082|\n",
      "| 33|      2|  5|      76|       1|   -1|       0| 7.0|    0.0|      0.0|    0.0|    0.0| 1.0|    1.0|  0.0|     0.0|0.0|[33.0,5.0,76.0,1....| 1073.070910435676|\n",
      "| 47|   1506|  5|      92|       1|   -1|       0| 0.0|    0.0|      3.0|    0.0|    0.0| 0.0|    1.0|  0.0|     0.0|0.0|[47.0,5.0,92.0,1....|  1470.22778587604|\n",
      "| 33|      1|  5|     198|       1|   -1|       0|11.0|    1.0|      3.0|    0.0|    1.0| 0.0|    1.0|  0.0|     0.0|0.0|[33.0,5.0,198.0,1...|1103.4279776401763|\n",
      "| 35|    231|  5|     139|       1|   -1|       0| 1.0|    0.0|      1.0|    0.0|    0.0| 0.0|    1.0|  0.0|     0.0|0.0|[35.0,5.0,139.0,1...|1144.9150466952042|\n",
      "| 28|    447|  5|     217|       1|   -1|       0| 1.0|    1.0|      1.0|    0.0|    0.0| 1.0|    1.0|  0.0|     0.0|0.0|[28.0,5.0,217.0,1...| 967.7358530699978|\n",
      "| 42|      2|  5|     380|       1|   -1|       0| 7.0|    2.0|      1.0|    1.0|    0.0| 0.0|    1.0|  0.0|     0.0|0.0|[42.0,5.0,380.0,1...| 1401.470506207587|\n",
      "| 58|    121|  5|      50|       1|   -1|       0| 5.0|    0.0|      2.0|    0.0|    0.0| 0.0|    1.0|  0.0|     0.0|0.0|[58.0,5.0,50.0,1....|1768.7006942464907|\n",
      "| 43|    593|  5|      55|       1|   -1|       0| 2.0|    1.0|      0.0|    0.0|    0.0| 0.0|    1.0|  0.0|     0.0|0.0|[43.0,5.0,55.0,1....|1348.6852427110862|\n",
      "+---+-------+---+--------+--------+-----+--------+----+-------+---------+-------+-------+----+-------+-----+--------+---+--------------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# prediction result\n",
    "reg_model.transform(linear_df).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-collinearity with VIF (Variance Inflation Factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vif_calculator(df, features_list):\n",
    "    vif_list = []\n",
    "    for i in features_list:\n",
    "        temp_features_list = features_list.copy()\n",
    "        temp_features_list.remove(i)\n",
    "        temp_target = i\n",
    "        assembler = VectorAssembler(inputCols = temp_features_list, outputCol = 'features')\n",
    "        temp_df = assembler.transform(df)\n",
    "        reg = LinearRegression(featuresCol = 'features', labelCol = i)\n",
    "        reg_model = reg.fit(temp_df) # fit model\n",
    "        temp_vif = 1/(1 - reg_model.summary.r2)\n",
    "        vif_list.append(temp_vif)\n",
    "    return vif_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age', 'day', 'duration', 'campaign', 'pdays', 'previous']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df['vif'] = vif_calculator(linear_df.drop('features'), features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   idx      name  coefficients       vif\n",
      "0    0       age     28.083973  1.000917\n",
      "1    1       day      3.305546  1.034350\n",
      "2    2  duration      0.248828  1.007627\n",
      "3    3  campaign    -14.142676  1.039907\n",
      "4    4     pdays     -0.082488  1.276182\n",
      "5    5  previous     23.462993  1.261321\n"
     ]
    }
   ],
   "source": [
    "print(features_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'balance',\n",
       " 'day',\n",
       " 'duration',\n",
       " 'campaign',\n",
       " 'pdays',\n",
       " 'previous',\n",
       " 'job',\n",
       " 'marital',\n",
       " 'education',\n",
       " 'default',\n",
       " 'housing',\n",
       " 'loan',\n",
       " 'contact',\n",
       " 'month',\n",
       " 'poutcome',\n",
       " 'y']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transformed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_df = df_transformed.select(*num_cols, 'y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous', 'y']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols = logistic_df.columns[0:-1], outputCol = 'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_df = assembler.transform(logistic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+--------+--------+-----+--------+---+------------------------------------+\n",
      "|age|balance|day|duration|campaign|pdays|previous|y  |features                            |\n",
      "+---+-------+---+--------+--------+-----+--------+---+------------------------------------+\n",
      "|58 |2143   |5  |261     |1       |-1   |0       |0.0|[58.0,2143.0,5.0,261.0,1.0,-1.0,0.0]|\n",
      "|44 |29     |5  |151     |1       |-1   |0       |0.0|[44.0,29.0,5.0,151.0,1.0,-1.0,0.0]  |\n",
      "|33 |2      |5  |76      |1       |-1   |0       |0.0|[33.0,2.0,5.0,76.0,1.0,-1.0,0.0]    |\n",
      "|47 |1506   |5  |92      |1       |-1   |0       |0.0|[47.0,1506.0,5.0,92.0,1.0,-1.0,0.0] |\n",
      "|33 |1      |5  |198     |1       |-1   |0       |0.0|[33.0,1.0,5.0,198.0,1.0,-1.0,0.0]   |\n",
      "|35 |231    |5  |139     |1       |-1   |0       |0.0|[35.0,231.0,5.0,139.0,1.0,-1.0,0.0] |\n",
      "|28 |447    |5  |217     |1       |-1   |0       |0.0|[28.0,447.0,5.0,217.0,1.0,-1.0,0.0] |\n",
      "|42 |2      |5  |380     |1       |-1   |0       |0.0|[42.0,2.0,5.0,380.0,1.0,-1.0,0.0]   |\n",
      "|58 |121    |5  |50      |1       |-1   |0       |0.0|[58.0,121.0,5.0,50.0,1.0,-1.0,0.0]  |\n",
      "|43 |593    |5  |55      |1       |-1   |0       |0.0|[43.0,593.0,5.0,55.0,1.0,-1.0,0.0]  |\n",
      "+---+-------+---+--------+--------+-----+--------+---+------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logistic_df.show(10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_clf = LogisticRegression(featuresCol='features', labelCol='y', family='binomial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_df = logistic_df.withColumn('y', col('y').cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_clf_model = binary_clf.fit(logistic_df) # fit binary model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+--------+--------+-----+--------+---+------------------------------------+----------------------------------------+-----------------------------------------+----------+\n",
      "|age|balance|day|duration|campaign|pdays|previous|y  |features                            |rawPrediction                           |probability                              |prediction|\n",
      "+---+-------+---+--------+--------+-----+--------+---+------------------------------------+----------------------------------------+-----------------------------------------+----------+\n",
      "|58 |2143   |5  |261     |1       |-1   |0       |0  |[58.0,2143.0,5.0,261.0,1.0,-1.0,0.0]|[2.1176813936656,-2.1176813936656]      |[0.8926098759774228,0.10739012402257708] |0.0       |\n",
      "|44 |29     |5  |151     |1       |-1   |0       |0  |[44.0,29.0,5.0,151.0,1.0,-1.0,0.0]  |[2.7078044172889126,-2.7078044172889126]|[0.9374855970560074,0.06251440294399248] |0.0       |\n",
      "|33 |2      |5  |76      |1       |-1   |0       |0  |[33.0,2.0,5.0,76.0,1.0,-1.0,0.0]    |[3.0691503292685907,-3.0691503292685907]|[0.9556021376439241,0.04439786235607592] |0.0       |\n",
      "|47 |1506   |5  |92      |1       |-1   |0       |0  |[47.0,1506.0,5.0,92.0,1.0,-1.0,0.0] |[2.843604467693428,-2.843604467693428]  |[0.9449871464900379,0.05501285350996222] |0.0       |\n",
      "|33 |1      |5  |198     |1       |-1   |0       |0  |[33.0,1.0,5.0,198.0,1.0,-1.0,0.0]   |[2.625449390946919,-2.625449390946919]  |[0.932481607860613,0.0675183921393869]   |0.0       |\n",
      "|35 |231    |5  |139     |1       |-1   |0       |0  |[35.0,231.0,5.0,139.0,1.0,-1.0,0.0] |[2.8155737819766693,-2.8155737819766693]|[0.9435116229144398,0.056488377085560225]|0.0       |\n",
      "|28 |447    |5  |217     |1       |-1   |0       |0  |[28.0,447.0,5.0,217.0,1.0,-1.0,0.0] |[2.5795562356758674,-2.5795562356758674]|[0.9295342079222086,0.0704657920777914]  |0.0       |\n",
      "|42 |2      |5  |380     |1       |-1   |0       |0  |[42.0,2.0,5.0,380.0,1.0,-1.0,0.0]   |[1.8918086180441176,-1.8918086180441176]|[0.8689616105322446,0.1310383894677553]  |0.0       |\n",
      "|58 |121    |5  |50      |1       |-1   |0       |0  |[58.0,121.0,5.0,50.0,1.0,-1.0,0.0]  |[2.960310647904224,-2.960310647904224]  |[0.9507485422745869,0.049251457725413124]|0.0       |\n",
      "|43 |593    |5  |55      |1       |-1   |0       |0  |[43.0,593.0,5.0,55.0,1.0,-1.0,0.0]  |[3.0439644472165983,-3.0439644472165983]|[0.9545212380721015,0.045478761927898556]|0.0       |\n",
      "+---+-------+---+--------+--------+-----+--------+---+------------------------------------+----------------------------------------+-----------------------------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "binary_clf_model.transform(logistic_df).show(10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.007959289992554713,3.7181275567506194e-05,-0.0016500733138635486,0.0036371977016167118,-0.128043283553752,0.0021135713490607728,0.0859380108519198]\n"
     ]
    }
   ],
   "source": [
    "print(binary_clf_model.coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.4699010654247706\n"
     ]
    }
   ],
   "source": [
    "print(binary_clf_model.intercept) #model intercept for binary model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "multinomial_clf = LogisticRegression(featuresCol = 'features', labelCol = 'y', family = 'multinomial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "multinomial_clf_model = multinomial_clf.fit(logistic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseMatrix([[-3.97962982e-03, -1.85907216e-05,  8.24926374e-04,\n",
      "              -1.81859931e-03,  6.40216709e-02, -1.05678834e-03,\n",
      "              -4.29688093e-02],\n",
      "             [ 3.97962982e-03,  1.85907216e-05, -8.24926374e-04,\n",
      "               1.81859931e-03, -6.40216709e-02,  1.05678834e-03,\n",
      "               4.29688093e-02]])\n"
     ]
    }
   ],
   "source": [
    "print(multinomial_clf_model.coefficientMatrix)  # coefficient of Class 0 and Class 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.7349520795817952,-1.7349520795817952]\n"
     ]
    }
   ],
   "source": [
    "print(multinomial_clf_model.interceptVector) # Intercepts of Class 0 and Class 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+--------+--------+-----+--------+---+------------------------------------+----------------------------------------+-----------------------------------------+----------+\n",
      "|age|balance|day|duration|campaign|pdays|previous|y  |features                            |rawPrediction                           |probability                              |prediction|\n",
      "+---+-------+---+--------+--------+-----+--------+---+------------------------------------+----------------------------------------+-----------------------------------------+----------+\n",
      "|58 |2143   |5  |261     |1       |-1   |0       |0  |[58.0,2143.0,5.0,261.0,1.0,-1.0,0.0]|[1.0588423047295485,-1.0588423047295485]|[0.8926101842349116,0.10738981576508844] |0.0       |\n",
      "|44 |29     |5  |151     |1       |-1   |0       |0  |[44.0,29.0,5.0,151.0,1.0,-1.0,0.0]  |[1.3539038318422276,-1.3539038318422276]|[0.9374857873151383,0.0625142126848616]  |0.0       |\n",
      "|33 |2      |5  |76      |1       |-1   |0       |0  |[33.0,2.0,5.0,76.0,1.0,-1.0,0.0]    |[1.5345766576108106,-1.5345766576108106]|[0.9556022643278618,0.044397735672138186]|0.0       |\n",
      "|47 |1506   |5  |92      |1       |-1   |0       |0  |[47.0,1506.0,5.0,92.0,1.0,-1.0,0.0] |[1.4218038058584317,-1.4218038058584317]|[0.944987309936393,0.055012690063606894] |0.0       |\n",
      "|33 |1      |5  |198     |1       |-1   |0       |0  |[33.0,1.0,5.0,198.0,1.0,-1.0,0.0]   |[1.312726132472422,-1.312726132472422]  |[0.9324817888063172,0.0675182111936829]  |0.0       |\n",
      "|35 |231    |5  |139     |1       |-1   |0       |0  |[35.0,231.0,5.0,139.0,1.0,-1.0,0.0] |[1.4077883661704753,-1.4077883661704753]|[0.9435117801610983,0.05648821983890172] |0.0       |\n",
      "|28 |447    |5  |217     |1       |-1   |0       |0  |[28.0,447.0,5.0,217.0,1.0,-1.0,0.0] |[1.2897794328282814,-1.2897794328282814]|[0.9295343801867074,0.07046561981329254] |0.0       |\n",
      "|42 |2      |5  |380     |1       |-1   |0       |0  |[42.0,2.0,5.0,380.0,1.0,-1.0,0.0]   |[0.9459057988991384,-0.9459057988991384]|[0.8689619498285217,0.13103805017147832] |0.0       |\n",
      "|58 |121    |5  |50      |1       |-1   |0       |0  |[58.0,121.0,5.0,50.0,1.0,-1.0,0.0]  |[1.4801571983286048,-1.4801571983286048]|[0.9507487178124665,0.049251282187533475]|0.0       |\n",
      "|43 |593    |5  |55      |1       |-1   |0       |0  |[43.0,593.0,5.0,55.0,1.0,-1.0,0.0]  |[1.5219838284579632,-1.5219838284579632]|[0.9545213774063717,0.04547862259362844] |0.0       |\n",
      "+---+-------+---+--------+--------+-----+--------+---+------------------------------------+----------------------------------------+-----------------------------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "multinomial_clf_model.transform(logistic_df).show(10,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(featuresCol = 'features', labelCol = 'y', impurity = 'gini') #gini based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_model = clf.fit(logistic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+--------+--------+-----+--------+---+------------------------------------+---------------+----------------------------------------+----------+\n",
      "|age|balance|day|duration|campaign|pdays|previous|y  |features                            |rawPrediction  |probability                             |prediction|\n",
      "+---+-------+---+--------+--------+-----+--------+---+------------------------------------+---------------+----------------------------------------+----------+\n",
      "|58 |2143   |5  |261     |1       |-1   |0       |0  |[58.0,2143.0,5.0,261.0,1.0,-1.0,0.0]|[8533.0,755.0] |[0.9187123169681309,0.08128768303186908]|0.0       |\n",
      "|44 |29     |5  |151     |1       |-1   |0       |0  |[44.0,29.0,5.0,151.0,1.0,-1.0,0.0]  |[19932.0,373.0]|[0.9816301403595173,0.01836985964048264]|0.0       |\n",
      "|33 |2      |5  |76      |1       |-1   |0       |0  |[33.0,2.0,5.0,76.0,1.0,-1.0,0.0]    |[19932.0,373.0]|[0.9816301403595173,0.01836985964048264]|0.0       |\n",
      "|47 |1506   |5  |92      |1       |-1   |0       |0  |[47.0,1506.0,5.0,92.0,1.0,-1.0,0.0] |[19932.0,373.0]|[0.9816301403595173,0.01836985964048264]|0.0       |\n",
      "|33 |1      |5  |198     |1       |-1   |0       |0  |[33.0,1.0,5.0,198.0,1.0,-1.0,0.0]   |[19932.0,373.0]|[0.9816301403595173,0.01836985964048264]|0.0       |\n",
      "|35 |231    |5  |139     |1       |-1   |0       |0  |[35.0,231.0,5.0,139.0,1.0,-1.0,0.0] |[19932.0,373.0]|[0.9816301403595173,0.01836985964048264]|0.0       |\n",
      "|28 |447    |5  |217     |1       |-1   |0       |0  |[28.0,447.0,5.0,217.0,1.0,-1.0,0.0] |[1664.0,129.0] |[0.928053541550474,0.07194645844952594] |0.0       |\n",
      "|42 |2      |5  |380     |1       |-1   |0       |0  |[42.0,2.0,5.0,380.0,1.0,-1.0,0.0]   |[8533.0,755.0] |[0.9187123169681309,0.08128768303186908]|0.0       |\n",
      "|58 |121    |5  |50      |1       |-1   |0       |0  |[58.0,121.0,5.0,50.0,1.0,-1.0,0.0]  |[19932.0,373.0]|[0.9816301403595173,0.01836985964048264]|0.0       |\n",
      "|43 |593    |5  |55      |1       |-1   |0       |0  |[43.0,593.0,5.0,55.0,1.0,-1.0,0.0]  |[19932.0,373.0]|[0.9816301403595173,0.01836985964048264]|0.0       |\n",
      "+---+-------+---+--------+--------+-----+--------+---+------------------------------------+---------------+----------------------------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_model.transform(logistic_df).show(10,False) #future predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7,[0,2,3,4,5],[0.07029188881576587,0.015298882843227956,0.7092650456120744,0.0029936718415604106,0.2021505108873715])\n"
     ]
    }
   ],
   "source": [
    "print(clf_model.featureImportances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = DecisionTreeRegressor(featuresCol='features', labelCol='balance', impurity='variance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_model = reg.fit(linear_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6,[0,1,2,3,4,5],[0.3698438457163591,0.30424559689419733,0.1507290562998903,0.028890629842263742,0.12374645056225508,0.02254442068503449])\n"
     ]
    }
   ],
   "source": [
    "print(reg_model.featureImportances) #feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+--------+--------+-----+--------+----+-------+---------+-------+-------+----+-------+-----+--------+---+-----------------------------+------------------+\n",
      "|age|balance|day|duration|campaign|pdays|previous|job |marital|education|default|housing|loan|contact|month|poutcome|y  |features                     |prediction        |\n",
      "+---+-------+---+--------+--------+-----+--------+----+-------+---------+-------+-------+----+-------+-----+--------+---+-----------------------------+------------------+\n",
      "|58 |2143   |5  |261     |1       |-1   |0       |1.0 |0.0    |1.0      |0.0    |0.0    |0.0 |1.0    |0.0  |0.0     |0.0|[58.0,5.0,261.0,1.0,-1.0,0.0]|1937.1573236889692|\n",
      "|44 |29     |5  |151     |1       |-1   |0       |2.0 |1.0    |0.0      |0.0    |0.0    |0.0 |1.0    |0.0  |0.0     |0.0|[44.0,5.0,151.0,1.0,-1.0,0.0]|1348.3228379513014|\n",
      "|33 |2      |5  |76      |1       |-1   |0       |7.0 |0.0    |0.0      |0.0    |0.0    |1.0 |1.0    |0.0  |0.0     |0.0|[33.0,5.0,76.0,1.0,-1.0,0.0] |937.5397395002658 |\n",
      "|47 |1506   |5  |92      |1       |-1   |0       |0.0 |0.0    |3.0      |0.0    |0.0    |0.0 |1.0    |0.0  |0.0     |0.0|[47.0,5.0,92.0,1.0,-1.0,0.0] |1348.3228379513014|\n",
      "|33 |1      |5  |198     |1       |-1   |0       |11.0|1.0    |3.0      |0.0    |1.0    |0.0 |1.0    |0.0  |0.0     |0.0|[33.0,5.0,198.0,1.0,-1.0,0.0]|937.5397395002658 |\n",
      "|35 |231    |5  |139     |1       |-1   |0       |1.0 |0.0    |1.0      |0.0    |0.0    |0.0 |1.0    |0.0  |0.0     |0.0|[35.0,5.0,139.0,1.0,-1.0,0.0]|937.5397395002658 |\n",
      "|28 |447    |5  |217     |1       |-1   |0       |1.0 |1.0    |1.0      |0.0    |0.0    |1.0 |1.0    |0.0  |0.0     |0.0|[28.0,5.0,217.0,1.0,-1.0,0.0]|937.5397395002658 |\n",
      "|42 |2      |5  |380     |1       |-1   |0       |7.0 |2.0    |1.0      |1.0    |0.0    |0.0 |1.0    |0.0  |0.0     |0.0|[42.0,5.0,380.0,1.0,-1.0,0.0]|1348.3228379513014|\n",
      "|58 |121    |5  |50      |1       |-1   |0       |5.0 |0.0    |2.0      |0.0    |0.0    |0.0 |1.0    |0.0  |0.0     |0.0|[58.0,5.0,50.0,1.0,-1.0,0.0] |1937.1573236889692|\n",
      "|43 |593    |5  |55      |1       |-1   |0       |2.0 |1.0    |0.0      |0.0    |0.0    |0.0 |1.0    |0.0  |0.0     |0.0|[43.0,5.0,55.0,1.0,-1.0,0.0] |1348.3228379513014|\n",
      "+---+-------+---+--------+--------+-----+--------+----+-------+---------+-------+-------+----+-------+-----+--------+---+-----------------------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reg_model.transform(linear_df).show(10,False) #future predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier # Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(featuresCol='features', labelCol='y')\n",
    "clf_model = clf.fit(logistic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7,[0,1,2,3,4,5,6],[0.0712224558282332,0.021323757857823398,0.03467989305640842,0.6594593977720731,0.010004203459231179,0.15888984057433286,0.04442045145189777])\n"
     ]
    }
   ],
   "source": [
    "print(clf_model.featureImportances)\n",
    "# print(clf_model.toDebugString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import RandomForestRegressor # Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = RandomForestRegressor(featuresCol='features', labelCol='balance')\n",
    "reg_model = reg.fit(linear_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6,[0,1,2,3,4,5],[0.3809530638699519,0.20958069504046067,0.0970537166707919,0.07602969796561258,0.15345908416837026,0.08292374228481265])\n"
     ]
    }
   ],
   "source": [
    "print(reg_model.featureImportances)\n",
    "# print(reg_model.toDebugString)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-vs-Rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the base classifier.\n",
    "clf = RandomForestClassifier(featuresCol = 'features', labelCol = 'education')\n",
    "\n",
    "# instantiate the One Vs Rest Classifier.\n",
    "ovr = OneVsRest(classifier = clf, featuresCol = 'features', labelCol = 'education')\n",
    "\n",
    "# train the multiclass model.\n",
    "ovrModel = ovr.fit(train)\n",
    "\n",
    "# score the model on test data.\n",
    "predictions = ovrModel.transform(test)\n",
    "\n",
    "# obtain evaluator.\n",
    "evaluator = MulticlassClassificationEvaluator(metricName = \"accuracy\", labelCol = 'education')\n",
    "\n",
    "# compute the classification error on test data.\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
